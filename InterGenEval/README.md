# InterGenEval

InterGenEval is a framework for generating evaluation data for interaction video generation and evaluating the performance of generative models.

This framework consists of two main parts: data generation and evaluation.

ðŸ¤– [**Evaluation data generation**](#1-scenario-design)

ðŸ“Š [**Generated video evaluation of generative models**](#1-track-objects-involved-in-the-interaction)

### ðŸ–‡ Installation
```bash
conda create -n intergeneval python=3.10
conda activate intergeneval
cd InterGenEval
pip install -r requirements.txt
```

### Directory Structure Overview

**Important:** Throughout this documentation, `DATA_DIRECTORY` refers to the base directory containing evaluation data and results. The typical structure is:

```
DATA_DIRECTORY/
â”œâ”€â”€ EVAL_DATA/                    # Input evaluation data
â”‚   â””â”€â”€ {data_type}/              # e.g., data_type 1, data_type 2
â”‚       â”œâ”€â”€ images/               # Prompt Image for Image-to-Video Generation
â”‚       â”œâ”€â”€ meta.json/            # meta data for video
â”‚       â”œâ”€â”€ questions/            # Question JSON files (generated by question_generation.sh, used for question verification)
â”‚       â”œâ”€â”€ bbox_vis/             # bbox visualization(generated by detect.sh)
â”‚       â”œâ”€â”€ verify_vis/           # Verified bbox visualization(generated by verify.sh)
â”‚       â”œâ”€â”€ verify_results.json   # Verification results(generated by verify.sh)
â”‚       â”œâ”€â”€ masks/                # Masks according to bbox(generated by segment.sh)
â”‚       â”œâ”€â”€ masks_vis/            # Masks overlayed with image(generated by segment.sh)
â”‚
â”œâ”€â”€ EVAL_RESULTS/                 # Generated video results (after tracking and visualization)
â”‚   â””â”€â”€ {model_id}/                # e.g., cogvideox_2b, cogvideox_5b, wan2.1_I2V_14b
â”‚       â””â”€â”€ {data_type}/
â”‚           â”œâ”€â”€ eval_metas/        # Metadata files (used for emergence_disappearance and question_generation)
â”‚           â””â”€â”€ track_vis/         # Tracked video files (used for both evaluations)
â”‚
â”œâ”€â”€ OUTPUTS/                      # Raw generated videos (before tracking)
â”‚   â””â”€â”€ {model_id}/                # e.g., cogvideox_2b, cogvideox_5b, wan2.1_I2V_14b
â”‚       â””â”€â”€ {data_type}/           # e.g., data_type 1, data_type 2
â”‚
â””â”€â”€ SCORE_RESULTS/                 # Calculated scores and summaries
    â”œâ”€â”€ emergence_disappearance_results/    # Individual emergence/disappearance results
    â”œâ”€â”€ question_verification_results/     # Individual question verification results
    â”œâ”€â”€ emergence_disappearance_scores_summary.json
    â”œâ”€â”€ video_scores_summary.json
    â”œâ”€â”€ combined_scores_summary.json
    â””â”€â”€ model_averages_summary.json
```

**Example paths (replace with your actual paths):**
- `DATA_DIRECTORY` = `YOUR_DATA_DIRECTORY` (e.g., `/path/to/your/evaluation/data`)
- `EVAL_DATA` = `YOUR_DATA_DIRECTORY/EVAL_DATA`
- `EVAL_RESULTS` = `YOUR_DATA_DIRECTORY/EVAL_RESULTS`
- `OUTPUTS` = `YOUR_DATA_DIRECTORY/OUTPUTS`
- `SCORE_RESULTS` = `YOUR_DATA_DIRECTORY/SCORE_RESULTS`

**Important Notes:**
- You may need to modify the `DATA_DIRECTORY` to use your own `DATA_DIRECTORY`.
- The `OUTPUTS` directory contains raw generated videos before tracking and visualization.
- The `EVAL_RESULTS` directory contains processed results after tracking and visualization.

### Common Arguments

Throughout this documentation, the following arguments are used across multiple scripts:

- **`DATA_DIRECTORY`**: Base directory containing evaluation data and results
- **`GPU_ID`**: GPU device ID to use (e.g., `0`, `1`, `2`)
- **`MODEL_ID`**: Model name (e.g., `cogvideox_2b`, `cogvideox_5b`, `wan2.1_I2V_14b`)
- **`DATA_TYPE`**: Data type (e.g., `data_type 1`, `data_type 2`)
- **`MODEL_ID_LIST`**: Comma-separated list of model names (e.g., `"cogvideox_2b,cogvideox_5b,wan2.1_I2V_14b"`)
- **`DATA_TYPE_LIST`**: Comma-separated list of data types (e.g., `"data_type 1,data_type 2"`)
- **`PID`**: Process ID for distributed processing
- **`N_PIDS`**: Total number of processes for distributed processing
- **`COGVIDEOX_VERSION`**: Version of CogVideoX model (`2b` or `5b`)

## Generation of Evaluation Data

### Prerequisites: Preparing EVAL_DATA/{data_type}

Before running the evaluation pipeline, you need to prepare the following in `{DATA_DIRECTORY}/EVAL_DATA/{data_type}/`:

1. **`images/` directory**: Prompt images for image-to-video generation
   - Generated in step 2 below
   - Each image should correspond to a video scenario

2. **`meta.json` file**: Metadata file containing video scenarios and object information
   - Generated in step 1 below
   - Format: JSON array where each element contains:
     - `video_text_prompt`: Description of the video to be generated
     - `image_text_prompt`: Description of the prompt image (before interaction)
     - `interaction_direction`: `"unidirectional"` or `"bidirectional"`
     - `num_objects`: Number of objects involved in the interaction
     - `interaction_type`: Type of interaction (e.g., `"manipulation"`, `"contact"`, `"force"`, `"transport_move"`, `"social_contact"`)
     - `objects`: Array of objects with `class` and `appearance` fields

**Example `meta.json` structure:**
```json
[
  {
    "video_text_prompt": "The man in a gray T-shirt with short black hair opens the silver fridge door in the kitchen.",
    "image_text_prompt": "The man in a gray T-shirt with short black hair stands near the silver fridge before opening it, keeping his hand not touching the handle.",
    "interaction_direction": "unidirectional",
    "num_objects": 2,
    "interaction_type": "manipulation",
    "objects": [
      { "class": "man", "appearance": "man in a gray T-shirt with short black hair" },
      { "class": "fridge", "appearance": "silver fridge door" }
    ]
  },
  ...
]
```

## ðŸ¤– Evaluation data generation
### 1. Scenario Design
We use VLMs (e.g., GPT5o, Gemini) to create a detailed interaction scenarios.
In this stage, the goal is to design the *first-frame image* where the interaction has **not yet begun**, but all relevant entities are present and well-positioned. These scenarios should be formatted as a `meta.json` file (see structure above) and saved to `{DATA_DIRECTORY}/EVAL_DATA/{data_type}/meta.json`.

We recommend the following scenarios that categorized into:
- contact (e.g., touching, holding)
- force (e.g., pushing, pulling)
- transport (e.g., handling over, carrying), 
- manipulation (e.g, cutting, opening),
- social (e.g., hugging, waving)

To ensure class diversity, we include human-object, human-human, human-animal, human-nature interactions, encouraging generalization beyond human-centric scenarios.

### 2. Prompt Construction
We then use VLMs (e.g., GPT5o, Gemini) to construct **interaction-aware prompts** conditioned on the designed first frame. These prompts specify instance identities, class labels, and concise descriptors. Use Gemini to create detailed prompt images based on the `image_text_prompt` from `meta.json`. Save the generated images to `{DATA_DIRECTORY}/EVAL_DATA/{data_type}/images/` directory. Each image should be named to correspond with its scenario (e.g., `000.png`, `001.png`, etc.).

(1) Static image prompt : Compose an image prompt that captures the static scene and instance attributes.

(2) Motion-aware video prompt : Derive a motion-aware video prompt by adding action and relation clauses (subject-verb-object) with temporal qualifiers (e.g., contact). 

(3) Prompt refinement: Enhance prompt while preserving instance IDS and interaction roles. 

### 3. Pseudo Ground-Truth Generation 
In this stage, we generate pseudo ground-truth instance masks for the interacting entities.
####  Detect Objects Involved in the Interaction from Video
Use GroundingDINO to detect and localize the target instances in each frame.
```bash
sh scripts/detect.sh [GPU_ID] [DATA_DIRECTORY] [DATA_TYPE]
```
#### Verify Objects Involved in the Interaction
Use a VLM (e.g., GPT-5o) to verify whether each detected instance actually corresponds to the queried interacting object.
```bash
sh scripts/verify.sh [DATA_DIRECTORY] [DATA_TYPE] 
```
#### Segment Objects Involved in the Interaction
After verification, segment the objects using SAM2.
```bash
sh scripts/segment.sh [GPU_ID] [DATA_DIRECTORY] [DATA_TYPE]
```
#### [Additional] Segment Objects Manually
If the above automatic steps are not available or fail, you can manually segment objects using the provided script.
```bash
sh scripts/manual_segment.sh [GPU_ID] [DATA_DIRECTORY] [DATA_TYPE]
```

## ðŸ“Š Generated video evaluation of generative models

### 1. Track Objects Involved in the Interaction
Use SAM2 to propagate the interacting object across video frames.
```bash
sh scripts/track.sh [GPU_ID] [DATA_DIRECTORY] [VIDEO_TYPE] [DATA_TYPE]
```
**Note:** If needed, you can use the `--center_crop` option by modifying `track.sh` or directly calling `track_object.py` with the `--center_crop` flag. This option center crops the image to 1024x1024, which can be useful when the generated video dimensions differ from the original mask dimensions.

### 2. Visualize Tracked Objects
To verify that tracking is successful, visualize the tracked objects overlaid on the video.
```bash
sh scripts/visualize.sh [DATA_DIRECTORY] [VIDEO_TYPE] [DATA_TYPE]
```

### 3. Evaluate SPI (Emergence/Disappearance Detection)

**Processing Mode:** The script processes one model and data type combination per execution. To process all models and data types, you need to run the script multiple times (once for each combination) or use a loop/wrapper script.

**Input:**
- `metas_dir`: `{DATA_DIRECTORY}/EVAL_RESULTS/{model_id}/{data_type}/eval_metas`
- `videos_dir`: `{DATA_DIRECTORY}/EVAL_RESULTS/{model_id}/{data_type}/track_vis`

**Output Structure:**
```
{DATA_DIRECTORY}/SCORE_RESULTS/emergence_disappearance_results/
â””â”€â”€ {model_id}/                    # Model name (e.g., cogvideox_2b, cogvideox_5b, wan2.1_I2V_14b)
    â””â”€â”€ {data_type}/               # Data type (e.g., data_type 1, data_type 2)
        â””â”€â”€ _emergence_disappearance.json
```

**Usage:**
```bash
sh scripts/emergence_disappearance.sh [DATA_DIRECTORY] [MODEL_ID] [DATA_TYPE]
```

**Note:** The script uses a default stride of 5 for frame sampling. If you need to adjust the stride, modify the `--stride` parameter in `emergence_disappearance.sh` or call `emergence_disappearance.py` directly with your desired stride value.

**Example:**
```bash
# Process one model and data type at a time
sh scripts/emergence_disappearance.sh YOUR_DATA_DIRECTORY cogvideox_2b "data_type 1"
sh scripts/emergence_disappearance.sh YOUR_DATA_DIRECTORY cogvideox_2b "data_type 2"
sh scripts/emergence_disappearance.sh YOUR_DATA_DIRECTORY cogvideox_5b "data_type 1"

# Or use a loop to process all combinations
for model in cogvideox_2b cogvideox_5b wan2.1_I2V_14b; do
    for data_type in "data_type 1" "data_type 2"; do
        sh scripts/emergence_disappearance.sh YOUR_DATA_DIRECTORY $model "$data_type"
    done
done
```

**Note:** 
- Each execution processes one model and data type combination.
- Output is saved to `{DATA_DIRECTORY}/SCORE_RESULTS/emergence_disappearance_results/`

### 5. Question Generation for KISA, SGI

**Usage:**
```bash
sh scripts/question_generation.sh [DATA_DIRECTORY] [MODEL_ID] [DATA_TYPE]
```

**Input:**
- `metas_dir`: `{DATA_DIRECTORY}/EVAL_DATA/{data_type}/eval_metas`

**Output:** `{DATA_DIRECTORY}/EVAL_DATA/{data_type}/questions/` directory (one JSON file per video: `000.json`, `001.json`, etc.)

**Note:** The script generates individual JSON files for each video in the `questions/` directory, which are used in question verification.

### 6. Evaluate KISA, SGI (Question Verification)

**Processing Mode:** Processes one model and data type at a time (must be run separately for each combination).

**Input:**
- `metas_dir`: `{DATA_DIRECTORY}/EVAL_DATA/{data_type}/questions`
- `videos_dir`: `{DATA_DIRECTORY}/EVAL_RESULTS/{model_id}/{data_type}/track_vis`

**Output Structure:**
```
{DATA_DIRECTORY}/SCORE_RESULTS/question_verification_results/
â””â”€â”€ {model_id}/                    # Model name (e.g., cogvideox_2b, cogvideox_5b, wan2.1_I2V_14b)
    â””â”€â”€ {data_type}/               # Data type (e.g., data_type 1, data_type 2)
        â”œâ”€â”€ question_verification.json
        â””â”€â”€ video_scores.json      # Generated by calculate_KISA_SGI_scores.sh
```

**Usage:**
```bash
sh scripts/question_verification.sh [DATA_DIRECTORY] [MODEL_ID] [DATA_TYPE]
```

**Note:** The script uses a default stride of 5 for frame sampling. If you need to adjust the stride, modify the `--stride` parameter in `question_verification.sh` or call `question_verification.py` directly with your desired stride value.

**Example:**
```bash
# Process each model and data type separately
sh scripts/question_verification.sh YOUR_DATA_DIRECTORY cogvideox_2b "data_type 1"
sh scripts/question_verification.sh YOUR_DATA_DIRECTORY cogvideox_2b "data_type 2"
sh scripts/question_verification.sh YOUR_DATA_DIRECTORY cogvideox_5b "data_type 1"
```

**Note:** 
- Each execution processes one model and data type combination.
- Output is saved to `{DATA_DIRECTORY}/SCORE_RESULTS/question_verification_results/`
- The script must be run separately for each model and data type you want to evaluate.

### 7. Calculate SPI Scores

Aggregates all emergence/disappearance results into a summary JSON file.

**Input:** `{DATA_DIRECTORY}/SCORE_RESULTS/emergence_disappearance_results/` directory (structure shown in step 4)

**Output:** `{DATA_DIRECTORY}/SCORE_RESULTS/emergence_disappearance_scores_summary.json`

**Usage:**
```bash
sh scripts/calculate_SPI_scores.sh [DATA_DIRECTORY]
```

**Or with custom paths:**
```bash
python calculate_emergence_disappearance_scores.py \
    --base-dir YOUR_PATH_TO/SCORE_RESULTS/emergence_disappearance_results \
    --output-file YOUR_PATH_TO/SCORE_RESULTS/emergence_disappearance_scores_summary.json
```

### 8. Calculate KISA, SGI Scores

Calculates scores from question verification results and reorganizes them. Processes all combinations of model IDs and data types automatically.

**Input:** `{DATA_DIRECTORY}/SCORE_RESULTS/question_verification_results/` directory (structure shown in step 6)

**Output:** `{DATA_DIRECTORY}/SCORE_RESULTS/video_scores_summary.json`

**Usage:**
```bash
sh scripts/calculate_KISA_SGI_scores.sh [DATA_DIRECTORY] [MODEL_ID_LIST] [DATA_TYPE_LIST]
```

**Example:**
```bash
# Process all combinations of models and data types
sh scripts/calculate_KISA_SGI_scores.sh \
    YOUR_DATA_DIRECTORY \
    "cogvideox_2b,cogvideox_5b,wan2.1_I2V_14b" \
    "data_type 1,data_type 2"

# Single model and data type
sh scripts/calculate_KISA_SGI_scores.sh \
    YOUR_DATA_DIRECTORY \
    "cogvideox_2b" \
    "data_type 1"
```

**Note:** 
- The script automatically processes all combinations of the provided model IDs and data types.
- It calculates scores for each combination and then reorganizes all results into a summary file.
- If an input file is missing, it will skip that combination with a warning.

**Or with custom paths:**
```bash
# Step 1: Calculate scores for one model/data_type
python calculate_question_verification_scores.py \
    --json-file YOUR_PATH_TO/question_verification_results/{model_id}/{data_type}/question_verification.json \
    --output-file YOUR_PATH_TO/question_verification_results/{model_id}/{data_type}/video_scores.json

# Step 2: Reorganize all video scores
python reorganize_video_scores.py \
    --base-dir YOUR_PATH_TO/question_verification_results \
    --output-file YOUR_PATH_TO/video_scores_summary.json
```

### 9. Calculate KISA_SPI, SGA_SPI, IF Scores

Combines video scores (KISA, SGA) with SPI scores to calculate final metrics.

**Input:**
- Video scores: `{DATA_DIRECTORY}/SCORE_RESULTS/video_scores_summary.json`
- SPI scores: `{DATA_DIRECTORY}/SCORE_RESULTS/emergence_disappearance_scores_summary.json`

**Output:** `{DATA_DIRECTORY}/SCORE_RESULTS/combined_scores_summary.json`

**Usage:**
```bash
sh scripts/calculate_combined_scores.sh [DATA_DIRECTORY]
```

**Or with custom paths:**
```bash
python calculate_combined_scores.py \
    --video-scores-file YOUR_PATH_TO/SCORE_RESULTS/video_scores_summary.json \
    --emergence-scores-file YOUR_PATH_TO/SCORE_RESULTS/emergence_disappearance_scores_summary.json \
    --output-file YOUR_PATH_TO/SCORE_RESULTS/combined_scores_summary.json
```

### 10. Calculate Model Averages

Calculates average KISA_SPI, SGA_SPI, and IF_score for each model across all data types from the combined scores summary.

**Input:** `{DATA_DIRECTORY}/SCORE_RESULTS/combined_scores_summary.json`

**Output:** `{DATA_DIRECTORY}/SCORE_RESULTS/model_averages_summary.json`

The output includes:
- Overall averages for each model (across all data types)
- Breakdown by sample type (data type) for each model
- Total number of videos processed per model

**Usage:**
```bash
sh scripts/calculate_model_averages.sh [DATA_DIRECTORY]
```

**Example:**
```bash
sh scripts/calculate_model_averages.sh YOUR_DATA_DIRECTORY
```

**Or with custom paths:**
```bash
python calculate_model_averages.py \
    --base_dir YOUR_PATH_TO/SCORE_RESULTS \
    --output_file YOUR_PATH_TO/SCORE_RESULTS/model_averages_summary.json \
    --input_file YOUR_PATH_TO/SCORE_RESULTS/combined_scores_summary.json
```

**Note:**
- The script processes all models and data types from the combined scores summary.
- Results include both overall averages and per-sample-type breakdowns.
- The output file can be used for model comparison and ranking.

## Summary of Output Directory Structures

### Score Results Directory Structure
```
{DATA_DIRECTORY}/SCORE_RESULTS/
â”œâ”€â”€ emergence_disappearance_results/
â”‚   â”œâ”€â”€ {model_id}/                     # Your model name (e.g., cogvideox_2b, cogvideox_5b, wan2.1_I2V_14b)
â”‚   â”‚   â”œâ”€â”€ data_type 1/
â”‚   â”‚   â”‚   â””â”€â”€ _emergence_disappearance.json
â”‚   â”‚   â””â”€â”€ data_type 2/
â”‚   â”‚       â””â”€â”€ _emergence_disappearance.json
â”‚   â”œâ”€â”€ {another_model_id}/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ question_verification_results/
â”‚   â”œâ”€â”€ {model_id}/                     # Your model name (e.g., cogvideox_2b, cogvideox_5b, wan2.1_I2V_14b)
â”‚   â”‚   â”œâ”€â”€ data_type 1/
â”‚   â”‚   â”‚   â”œâ”€â”€ question_verification.json
â”‚   â”‚   â”‚   â””â”€â”€ video_scores.json
â”‚   â”‚   â””â”€â”€ data_type 2/
â”‚   â”‚       â”œâ”€â”€ question_verification.json
â”‚   â”‚       â””â”€â”€ video_scores.json
â”‚   â”œâ”€â”€ {another_model_id}/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ emergence_disappearance_scores_summary.json
â”œâ”€â”€ video_scores_summary.json
â”œâ”€â”€ combined_scores_summary.json
â””â”€â”€ model_averages_summary.json
```